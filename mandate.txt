I am giving you a mandate. We are going to completely revamp this application. I have seen the wisdom of AWS lambda we are going to use generous free tier to host this application instead of Ruby on rails we are also going to use the native iOS text to speech and speech to text tools in order to get this application to finish this way we can remove dependency on network requests as well as external API providers so the new statement of work is what we will have will be Ira. We want to streamline it so user flow number one basic interview. The user will go to the home screen say watch new interview. Hear the user will then be asked. What do they wanna talk about important do not display the text before submitting it just automatically submit the text in the background. It will feel more magical if we increase automation in that respect we want it to feel magical and will risk the basic feel of the application is fine but the way that we have it No then so once they launch the interview, we will use apples speech to text and then we will send that up in a request to Landa. Landa will make a request to Gemini flashlight the way we're doing now except we should probably not use a ruby runtime. We should probably use a different runtime for the land so we need to evaluate what the best land runtime are then once those questions come back, we will not be using Groc transcription and instead will be using Apple transcription Apple transcription will be transcribing things. We also don't need to persist anything to a remote database. I think I was just being a hampered it. It'll address privacy concerns if we're persisting anything to remote databases and then yeah so we just wanna we wanna move we don't really need a back in anymore the whole point that with serverless we won't be using a backend we will be using serverless and then the Apple native transcription speech to text. We do still wanna have a voice select, but I think we just wanna have a default voice and then selecting a voice isn't like a step for watching the interview because this will add friction to get into our primary user flow we wanted to be as quick as possible so just have one default voice, and then voice select will be an option on the homepage, and then the interviews will be spoken by default and then instead of like making them choose in advance. They'll just be like like a little toggle on the interview page that will be like turn voice Off and then that'll be like really free and easy and then that's pretty much it. We need revenue, cat and then AWS Coquito for getting the people to login. I think we logged them in. I think we want anonymous users. I think they have to be logged into use it and then we'll like define a free tier later on and then one thing that I never saw that we implemented is I want the audio files to be persisted on the device and then yeah we want to store those audio files on device only and then they wanna be able to listen to their audio files afterwards and then we especially wanna be able to stitch them together doing this work on device, of course in order to be able to like you know they're gonna be able to want the podcast and then I haven't rolled out the idea of the audio remaster as a premium feature, but we want to be able to do that work on device so I think we only will ask for the rock word level transcript yeah I don't know. I mean that's a premium feature. I just wanna do this. I don't think I should just ship this cause like a guy on hacker news he posted something that's very relevant to what this was and then I mean the thing is like my costs are going down so much that like I don't know that I can really in good conscience like charge $10 a month for this, but I mean because the future set and the cost are both going down so I don't know if people are gonna want my features or not but like anyway we just so the only the only AWS and point the only lamb out point is like make Gemini request and then everything else all of that passing of the Gemini request even sending the prompt we're just going to hardcode that knowledge into the swift app like I mean actually I guess I can reduce network throughput if lamb up like contain some of the prompt text and then only the input text will be go actually I have no idea. It's just a little bit of text right I mean just like another fucking hundred words like do I store it and lamb or do I store it in like fucking in the AWS device? I don't know like probably easier lambda must've some kind of memory store right like the thing is there's a prompt and then there's the input text and then those both have to be sent over and yeah, but like I really want the user to be able to like see the audio like and then I have the audio persisted within the mobile experience like we wanted to be just as good as like a fucking voice recording app and then you know I really I looked at like the default Mac app and like it has like a very default like fucking waveform this way for like does it has a vertical line and then the spoken audio scrolls to the left and I thought that like we should just copy that exact basic way form all all the way forms I was doing up until now we're stupid but like you know it just scrolls to the left and then you can see it like get bigger and smaller and it's got like like a one second like this is what people expect when they're doing audio recording so I think we just do like some some permutation or like freestyle re-skin version of that then I'll match like our color sc but yeah, the audio needs to be playable on the device and then you know all of the all of the transcriptions will be done with with Apple, so the speech to text will be done with Apple and then the text to speech will be done with Apple or the speech to text so all the transcription should still be the same and then I think probably like I should make some kind of like editable daily questions feature or like you know it's like a daily journal like what or they can or they can edit it and then they'll be able to like have like fine-grained control of what the daily questions are that they're being asked I think that's a Allie just thinks this is a crock of shit. I can tell she has no patience when I tell her about it, but like, yeah just yeah just I'll just have Claude work this over.

Yeah, I mean just to be clear. There will be no fucking rub on rails back and the Rubine rails back and will be totally replaced with on device processing and they're just a simple backend that just does authentication forwarding request to Gemini then possibly some other stuff, but we just wanna pair it down as much as possible. This will address both server costs and privacy concerns so I'm only including the Ruby on rails architecture here for reference because that's where we're coming from. it will be completely removed.